# -*- coding: utf-8 -*-
"""summary scraper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IPepJYMP1WRDX_FD7UbQOE_zrfZa5T66
"""

!pip install youtube-transcript-api whisper transformers langdetect deep-translator

import os
from youtube_transcript_api import YouTubeTranscriptApi
import whisper
from langdetect import detect
from deep_translator import GoogleTranslator
from transformers import PegasusForConditionalGeneration, PegasusTokenizer

# Function to fetch YouTube transcript
def fetch_youtube_transcript(video_id):
    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        text = " ".join([entry['text'] for entry in transcript])
        return text
    except Exception as e:
        print(f"Error fetching transcript: {e}")
        return None

# Function to transcribe audio using Whisper
def transcribe_audio(file_path, model_size="base"):
    model = whisper.load_model(model_size)
    result = model.transcribe(file_path)
    return result["text"]

# Function to clean and preprocess input text
def clean_text(text):
    # Remove tags like [Music], excessive repetition, and unnecessary whitespace
    text = text.replace("[Music]", "").strip()
    lines = text.splitlines()
    cleaned_lines = list(dict.fromkeys(lines))  # Remove exact duplicate lines
    return " ".join(cleaned_lines)

# Function for language detection and translation
def process_language(text, target_language="en"):
    source_language = detect(text)
    print(f"Detected language: {source_language}")

    if source_language != target_language:
        print(f"Translating from {source_language} to {target_language}...")
        text = GoogleTranslator(source=source_language, target=target_language).translate(text)

    return text

# Function for summarization using Pegasus
def summarize_text(text, max_length=512):
    # Load Pegasus model and tokenizer
    model_name = "google/pegasus-xsum"
    tokenizer = PegasusTokenizer.from_pretrained(model_name)
    model = PegasusForConditionalGeneration.from_pretrained(model_name)

    # Tokenize and summarize the input
    tokens = tokenizer(text, truncation=True, padding="longest", return_tensors="pt")
    summary_ids = model.generate(tokens["input_ids"], max_length=max_length, num_beams=4, length_penalty=2.0, early_stopping=True)
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

# Main function to integrate all components
def summarize_youtube_video(video_url, target_language="en"):
    video_id = video_url.split("v=")[-1]  # Extract video ID from URL
    print(f"Processing video: {video_url}")

    text = fetch_youtube_transcript(video_id)

    if not text:
        print("Fetching transcript failed, attempting audio transcription...")
        # Add your audio file path (if available)
        audio_file_path = "path_to_downloaded_audio.mp4"
        text = transcribe_audio(audio_file_path)

    if not text:
        print("Failed to extract content from video.")
        return

    # Preprocess and translate text if needed
    text = clean_text(text)
    text = process_language(text, target_language)

    # Generate and display the summary
    summary = summarize_text(text)
    print("\n--- Summary ---\n")
    print(summary)

# Example Usage
if __name__ == "__main__":
    video_url = "https://www.youtube.com/watch?v=-0-30Ghhj-A"  # Replace with your video URL
    summarize_youtube_video(video_url)